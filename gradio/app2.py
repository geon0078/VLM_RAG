# app2.py


import os
os.environ["CUDA_VISIBLE_DEVICES"] = "1"  # ë‘ ë²ˆì§¸ GPUë§Œ ì‚¬ìš©

import gradio as gr
from models import load_all_models
from pipeline import run_rag_pipeline, run_vlm_only_pipeline
from PIL import Image

# --- 1. ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ ëª¨ë¸ ë¡œë”© ---
print(" ë¹„êµ ì•± ì‹œì‘... ëª¨ë“  ëª¨ë¸ ë¡œë”©ì„ ì‹œì‘í•©ë‹ˆë‹¤. ")
try:
    VLM, TXT_TOKENIZER, VIS_TOKENIZER, EMB_MODEL, DB_COLLECTION = load_all_models()
    print("âœ¨ ëª¨ë“  ëª¨ë¸ê³¼ DBê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤. Gradio UIë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. âœ¨")
    MODELS_LOADED = True
except Exception as e:
    print(f"ğŸš¨ ì¹˜ëª…ì  ì˜¤ë¥˜: ëª¨ë¸ ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. {e}")
    MODELS_LOADED = False

# --- 2. Gradio ì¸í„°í˜ì´ìŠ¤ë¥¼ ìœ„í•œ ë˜í¼(Wrapper) í•¨ìˆ˜ ---
def gradio_comparison_interface(image, user_question, progress=gr.Progress(track_tqdm=True)):
    """VLM ë‹¨ë… ë‹µë³€ê³¼ RAG ì ìš© ë‹µë³€ì„ ëª¨ë‘ ìƒì„±í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if not MODELS_LOADED:
        raise gr.Error("ëª¨ë¸ì´ ì •ìƒì ìœ¼ë¡œ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„œë²„ë¥¼ ì¬ì‹œì‘í•˜ê³  ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    
    progress(0, desc="VLM ë‹¨ë… ë‹µë³€ ìƒì„± ì¤‘...")
    # [ìˆ˜ì •] ì´ì œ vlm_only_pipelineì€ (ë‹µë³€, ê·¼ê±°) 2ê°œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    vlm_answer, vlm_reasoning = run_vlm_only_pipeline(image, user_question, VLM, TXT_TOKENIZER, VIS_TOKENIZER)
    
    # RAG ì ìš© íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    rag_answer, rag_desc, rag_context = run_rag_pipeline(
        image, user_question, VLM, TXT_TOKENIZER, VIS_TOKENIZER, EMB_MODEL, DB_COLLECTION, progress
    )
    
    # [ìˆ˜ì •] UI ì»´í¬ë„ŒíŠ¸ ìˆœì„œì— ë§ê²Œ ëª¨ë“  ê²°ê³¼ë¥¼ ë°˜í™˜
    return vlm_answer, vlm_reasoning, rag_answer, rag_desc, rag_context

# --- 3. Gradio UI êµ¬ì„± ---
with gr.Blocks(theme=gr.themes.Soft(), title="VLM vs RAG-VLM") as demo:
    gr.Markdown("# VLM vs RAG-VLM ë¹„êµ ë¶„ì„ ğŸ¤–")
    gr.Markdown("ë™ì¼í•œ ì´ë¯¸ì§€ì™€ ì§ˆë¬¸ì— ëŒ€í•´ VLM ë‹¨ë… ë‹µë³€ê³¼ RAG ì ìš© ë‹µë³€ì„ ë¹„êµí•©ë‹ˆë‹¤.")
    gr.Markdown("---")

    with gr.Row():
        with gr.Column(scale=1):
            gr.Markdown("## 1. ì…ë ¥")
            image_input = gr.Image(type="pil", label="ì´ë¯¸ì§€ ì—…ë¡œë“œ")
            question_input = gr.Textbox(label="ì§ˆë¬¸ ì…ë ¥", placeholder="ì´ë¯¸ì§€ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”...")
            submit_button = gr.Button("ê²°ê³¼ ë¹„êµí•˜ê¸°", variant="primary")
        
        with gr.Column(scale=1):
            gr.Markdown("## 2. VLM ë‹¨ë… ë‹µë³€")
            # [ìˆ˜ì •] linesì™€ max_linesë¥¼ í•¨ê»˜ ì§€ì •í•˜ì—¬ ìŠ¤í¬ë¡¤ë°” ìƒì„± ì œì–´
            vlm_answer_output = gr.Textbox(
                label="ëª¨ë¸ì˜ ìì²´ ì§€ì‹ ê¸°ë°˜ ë‹µë³€", interactive=False, lines=10, max_lines=15
            )
            with gr.Accordion("ë‹µë³€ ê·¼ê±° ë³´ê¸° (VLM)", open=False):
                # [ìˆ˜ì •] linesì™€ max_linesë¥¼ í•¨ê»˜ ì§€ì •
                vlm_reasoning_output = gr.Textbox(
                    label="VLMì˜ ì¶”ë¡  ê³¼ì •", interactive=False, lines=10, max_lines=15
                )

        with gr.Column(scale=1):
            gr.Markdown("## 3. RAG ì ìš© ë‹µë³€")
            # [ìˆ˜ì •] linesì™€ max_linesë¥¼ í•¨ê»˜ ì§€ì •
            rag_answer_output = gr.Textbox(
                label="ì§€ì‹ë² ì´ìŠ¤(DB) ì°¸ê³  ë‹µë³€", interactive=False, lines=10, max_lines=15
            )
            with gr.Accordion("ìƒì„¸ ê³¼ì • ë³´ê¸° (RAG)", open=False):
                # [ìˆ˜ì •] linesì™€ max_linesë¥¼ í•¨ê»˜ ì§€ì •
                rag_desc_output = gr.Textbox(
                    label="(1) ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼", interactive=False, lines=10, max_lines=15
                )
                # [ìˆ˜ì •] linesì™€ max_linesë¥¼ í•¨ê»˜ ì§€ì •
                rag_context_output = gr.Textbox(
                    label="(2) ì§€ì‹ë² ì´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼", interactive=False, lines=10, max_lines=15
                )

    if MODELS_LOADED:
        submit_button.click(
            fn=gradio_comparison_interface,
            inputs=[image_input, question_input],
            outputs=[vlm_answer_output, vlm_reasoning_output, rag_answer_output, rag_desc_output, rag_context_output]
        )
    else:
        gr.Markdown("## ğŸš¨ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨! ğŸš¨ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    demo.launch()