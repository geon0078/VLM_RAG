# v2/module/models.py
import torch
import chromadb
from sentence_transformers import SentenceTransformer
from transformers import AutoModelForCausalLM, AutoTokenizer
from ..config import VLM_MODEL_PATH, LLM_MODEL_PATH, EMBEDDING_MODEL_NAME, PERSIST_DIRECTORY, COLLECTION_NAMES

def load_models():
    """
    ì• í”Œë¦¬ì¼€ì´ì…˜ì— í•„ìš”í•œ ëª¨ë“  ëª¨ë¸(VLM, LLM, Embedding)ê³¼ DB ì»¤ë„¥ì…˜ì„ ë¡œë“œí•©ë‹ˆë‹¤.
    """
    # --- 1. VLM ë¡œë“œ ---
    print("1. VLM ëª¨ë¸ ë¡œë“œ ì¤‘... (Ovis)")
    vlm_model = AutoModelForCausalLM.from_pretrained(
        VLM_MODEL_PATH,
        torch_dtype=torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16,
        trust_remote_code=True,
        device_map="auto",
        low_cpu_mem_usage=True,
    )
    vlm_text_tokenizer = vlm_model.get_text_tokenizer()
    vlm_vis_tokenizer = vlm_model.get_visual_tokenizer()
    print("âœ… VLM ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")

    # --- 2. LLM ë¡œë“œ (í‚¤ì›Œë“œ ì¶”ì¶œìš©) ---
    print("2. LLM ëª¨ë¸ ë¡œë“œ ì¤‘... (Qwen)")
    llm_model = AutoModelForCausalLM.from_pretrained(
        LLM_MODEL_PATH,
        torch_dtype="auto",
        device_map="auto",
        trust_remote_code=True,
    )
    llm_tokenizer = AutoTokenizer.from_pretrained(LLM_MODEL_PATH, trust_remote_code=True)
    print("âœ… LLM ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")

    # --- 3. ì„ë² ë”© ëª¨ë¸ ë° ChromaDB ë¡œë“œ ---
    print("3. ì„ë² ë”© ëª¨ë¸ ë° ChromaDB ë¡œë“œ ì¤‘...")
    embedding_model = SentenceTransformer(EMBEDDING_MODEL_NAME)
    client = chromadb.PersistentClient(path=PERSIST_DIRECTORY)
    
    collections = {}
    for cname in COLLECTION_NAMES:
        try:
            cobj = client.get_collection(name=cname)
            print(f"âœ… ChromaDB ì»¬ë ‰ì…˜ '{cname}' ë¡œë“œ ì™„ë£Œ ({cobj.count()}ê°œ ë¬¸ì„œ).")
            collections[cname] = cobj
        except Exception as e:
            print(f"ğŸš¨ '{cname}' ì»¬ë ‰ì…˜ ë¡œë“œ ì‹¤íŒ¨: {e}")
            collections[cname] = None
    print("âœ… ì„ë² ë”© ëª¨ë¸ ë° ChromaDB ë¡œë“œ ì™„ë£Œ.")

    return {
        "vlm_model": vlm_model,
        "vlm_text_tokenizer": vlm_text_tokenizer,
        "vlm_vis_tokenizer": vlm_vis_tokenizer,
        "llm_model": llm_model,
        "llm_tokenizer": llm_tokenizer,
        "embedding_model": embedding_model,
        "collections": collections
    }