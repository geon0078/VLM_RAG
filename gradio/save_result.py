import os
import csv
import time
import logging
from PIL import Image
from typing import List, Dict, Optional, Tuple
from tqdm import tqdm
from contextlib import contextmanager

# GPU ì„¤ì •ì„ ìµœìƒë‹¨ìœ¼ë¡œ ì´ë™
os.environ["CUDA_VISIBLE_DEVICES"] = "1"  # ë‘ ë²ˆì§¸ GPUë§Œ ì‚¬ìš©

# ëª¨ë¸ ë° íŒŒì´í”„ë¼ì¸ ë¶ˆëŸ¬ì˜¤ê¸°
from models import load_all_models
from pipeline import run_vlm_only_pipeline, run_rag_pipeline

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# í´ë” ë° íŒŒì¼ ì„¤ì •
IMAGE_DIR = "./images"
QUESTION_CSV = "./questions.csv"
OUTPUT_CSV = "./vlm_rag_results.csv"

class ModelManager:
    """ëª¨ë¸ ìƒíƒœë¥¼ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""
    def __init__(self):
        self.models_loaded = False
        self.vlm = None
        self.txt_tokenizer = None
        self.vis_tokenizer = None
        self.emb_model = None
        self.collections = None
    
    def load_models(self) -> bool:
        """ëª¨ë“  ëª¨ë¸ì„ ë¡œë”©í•©ë‹ˆë‹¤."""
        try:
            logger.info("ğŸš€ ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘... ëª¨ë“  ëª¨ë¸ ë¡œë”©ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
            
            self.vlm, self.txt_tokenizer, self.vis_tokenizer, self.emb_model, self.collections = load_all_models()
            
            # ëª¨ë¸ ê²€ì¦
            if not self.validate_models():
                return False
            
            logger.info("âœ¨ ëª¨ë“  ëª¨ë¸ê³¼ DBê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤. ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
            self.models_loaded = True
            return True
            
        except Exception as e:
            logger.error(f"ğŸš¨ ì¹˜ëª…ì  ì˜¤ë¥˜: ëª¨ë¸ ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. {e}")
            self.models_loaded = False
            return False
    
    def validate_models(self) -> bool:
        """ëª¨ë¸ë“¤ì´ ì œëŒ€ë¡œ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸"""
        checks = [
            (self.vlm, "VLM ëª¨ë¸"),
            (self.txt_tokenizer, "í…ìŠ¤íŠ¸ í† í¬ë‚˜ì´ì €"),
            (self.vis_tokenizer, "ë¹„ì „ í† í¬ë‚˜ì´ì €"),
            (self.emb_model, "ì„ë² ë”© ëª¨ë¸"),
            (self.collections, "ì»¬ë ‰ì…˜")
        ]
        
        for model, name in checks:
            if model is None:
                logger.error(f"âŒ {name}ì´ ì œëŒ€ë¡œ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                return False
            logger.info(f"âœ… {name} ê²€ì¦ ì™„ë£Œ")
        
        return True
    
    def is_ready(self) -> bool:
        """ëª¨ë¸ì´ ì¤€ë¹„ë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
        return self.models_loaded

@contextmanager
def timer(operation_name: str):
    """ì‹œê°„ ì¸¡ì •ì„ ìœ„í•œ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
    start_time = time.time()
    try:
        yield start_time
    finally:
        end_time = time.time()
        elapsed_time = end_time - start_time
        logger.info(f"{operation_name} ì†Œìš” ì‹œê°„: {format_time(elapsed_time)}")

@contextmanager
def error_handler(operation_name: str):
    """ì—ëŸ¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
    try:
        yield
    except Exception as e:
        logger.error(f"{operation_name} ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise

def format_time(seconds: float) -> str:
    """ì‹œê°„ì„ ì‚¬ìš©ì ì¹œí™”ì ì¸ í˜•íƒœë¡œ í¬ë§·íŒ…"""
    if seconds < 1:
        return f"{seconds*1000:.0f}ms"
    elif seconds < 60:
        return f"{seconds:.1f}ì´ˆ"
    else:
        minutes = int(seconds // 60)
        remaining_seconds = seconds % 60
        return f"{minutes}ë¶„ {remaining_seconds:.1f}ì´ˆ"

def validate_inputs(image: Optional[Image.Image], question: str) -> None:
    """ì…ë ¥ê°’ ê²€ì¦"""
    if image is None:
        raise ValueError("ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    if not question or question.strip() == "":
        raise ValueError("ì§ˆë¬¸ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
    
    if len(question.strip()) < 3:
        raise ValueError("ì§ˆë¬¸ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ìµœì†Œ 3ê¸€ì ì´ìƒ í•„ìš”í•©ë‹ˆë‹¤.")

def load_questions_by_image(csv_path: str) -> Dict[str, List[str]]:
    """ì´ë¯¸ì§€ë³„ë¡œ ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜"""
    if not os.path.exists(csv_path):
        logger.error(f"âŒ ì§ˆë¬¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {csv_path}")
        return {}
    
    mapping = {}
    try:
        with open(csv_path, newline='', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row_num, row in enumerate(reader, 1):
                try:
                    img = row["image_name"].strip()
                    q = row["question"].strip()
                    if not img or not q:
                        logger.warning(f"ë¹ˆ ë°ì´í„° ê±´ë„ˆë›°ê¸° (í–‰ {row_num}): img='{img}', q='{q}'")
                        continue
                    mapping.setdefault(img, []).append(q)
                except KeyError as e:
                    logger.error(f"CSV ì»¬ëŸ¼ ì˜¤ë¥˜ (í–‰ {row_num}): {e}")
                    continue
    except Exception as e:
        logger.error(f"âŒ CSV íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
        return {}
    
    logger.info(f"ğŸ“‹ ì´ {len(mapping)}ê°œ ì´ë¯¸ì§€ì— ëŒ€í•œ ì§ˆë¬¸ì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤")
    return mapping

def safe_image_load(img_path: str) -> Optional[Image.Image]:
    """ì•ˆì „í•˜ê²Œ ì´ë¯¸ì§€ë¥¼ ë¡œë“œ"""
    try:
        if not os.path.exists(img_path):
            logger.warning(f"âš ï¸ ì´ë¯¸ì§€ íŒŒì¼ ì—†ìŒ: {img_path}")
            return None
        
        image = Image.open(img_path).convert("RGB")
        logger.debug(f"âœ… ì´ë¯¸ì§€ ë¡œë“œ ì„±ê³µ: {img_path} (í¬ê¸°: {image.size})")
        return image
        
    except Exception as e:
        logger.error(f"âŒ ì´ë¯¸ì§€ ì—´ê¸° ì‹¤íŒ¨: {img_path} - {e}")
        return None

def debug_model_state(model_manager: ModelManager, operation: str):
    """ëª¨ë¸ ìƒíƒœë¥¼ ë””ë²„ê¹…í•˜ëŠ” í•¨ìˆ˜"""
    logger.info(f"ğŸ” {operation} - ëª¨ë¸ ìƒíƒœ ì²´í¬:")
    logger.info(f"   - VLM: {type(model_manager.vlm)} ({'OK' if model_manager.vlm is not None else 'NONE'})")
    logger.info(f"   - txt_tokenizer: {type(model_manager.txt_tokenizer)} ({'OK' if model_manager.txt_tokenizer is not None else 'NONE'})")
    logger.info(f"   - vis_tokenizer: {type(model_manager.vis_tokenizer)} ({'OK' if model_manager.vis_tokenizer is not None else 'NONE'})")
    logger.info(f"   - emb_model: {type(model_manager.emb_model)} ({'OK' if model_manager.emb_model is not None else 'NONE'})")
    logger.info(f"   - collections: {type(model_manager.collections)} ({'OK' if model_manager.collections is not None else 'NONE'})")

def safe_run_vlm_pipeline(image, question, vlm, txt_tokenizer, vis_tokenizer):
    """VLM íŒŒì´í”„ë¼ì¸ì„ ì•ˆì „í•˜ê²Œ ì‹¤í–‰"""
    try:
        # íŒŒë¼ë¯¸í„° ê²€ì¦
        if vlm is None:
            raise ValueError("VLM ëª¨ë¸ì´ Noneì…ë‹ˆë‹¤")
        if txt_tokenizer is None:
            raise ValueError("í…ìŠ¤íŠ¸ í† í¬ë‚˜ì´ì €ê°€ Noneì…ë‹ˆë‹¤")
        if vis_tokenizer is None:
            raise ValueError("ë¹„ì „ í† í¬ë‚˜ì´ì €ê°€ Noneì…ë‹ˆë‹¤")
        
        logger.debug("VLM íŒŒì´í”„ë¼ì¸ íŒŒë¼ë¯¸í„° ê²€ì¦ ì™„ë£Œ")
        
        return run_vlm_only_pipeline(image, question, vlm, txt_tokenizer, vis_tokenizer)
    
    except Exception as e:
        logger.error(f"VLM íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        logger.error(f"ìƒì„¸ íŠ¸ë ˆì´ìŠ¤ë°±:\n{traceback.format_exc()}")
        raise

class DummyProgress:
    """ë°°ì¹˜ ì²˜ë¦¬ìš© ë”ë¯¸ progress ê°ì²´"""
    def __call__(self, value, desc=""):
        logger.debug(f"[Progress] {desc} - {value*100:.1f}%")
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        pass

def safe_run_rag_pipeline(image, question, vlm, txt_tokenizer, vis_tokenizer, emb_model, collections):
    """RAG íŒŒì´í”„ë¼ì¸ì„ ì•ˆì „í•˜ê²Œ ì‹¤í–‰"""
    try:
        # íŒŒë¼ë¯¸í„° ê²€ì¦
        if vlm is None:
            raise ValueError("VLM ëª¨ë¸ì´ Noneì…ë‹ˆë‹¤")
        if txt_tokenizer is None:
            raise ValueError("í…ìŠ¤íŠ¸ í† í¬ë‚˜ì´ì €ê°€ Noneì…ë‹ˆë‹¤")
        if vis_tokenizer is None:
            raise ValueError("ë¹„ì „ í† í¬ë‚˜ì´ì €ê°€ Noneì…ë‹ˆë‹¤")
        if emb_model is None:
            raise ValueError("ì„ë² ë”© ëª¨ë¸ì´ Noneì…ë‹ˆë‹¤")
        if collections is None:
            raise ValueError("ì»¬ë ‰ì…˜ì´ Noneì…ë‹ˆë‹¤")
        
        logger.debug("RAG íŒŒì´í”„ë¼ì¸ íŒŒë¼ë¯¸í„° ê²€ì¦ ì™„ë£Œ")
        
        # ì»¬ë ‰ì…˜ ìƒíƒœ í™•ì¸
        if hasattr(collections, '__len__'):
            logger.debug(f"ì»¬ë ‰ì…˜ ê°œìˆ˜: {len(collections)}")
        elif hasattr(collections, 'keys'):
            logger.debug(f"ì»¬ë ‰ì…˜ í‚¤: {list(collections.keys())}")
        
        # ë”ë¯¸ progress ê°ì²´ ìƒì„± (None ëŒ€ì‹  ì‚¬ìš©)
        dummy_progress = DummyProgress()
        
        return run_rag_pipeline(
            image, question, vlm, txt_tokenizer, vis_tokenizer, 
            emb_model, collections, progress=dummy_progress
        )
    
    except Exception as e:
        logger.error(f"RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        logger.error(f"ìƒì„¸ íŠ¸ë ˆì´ìŠ¤ë°±:\n{traceback.format_exc()}")
        raise

def process_single_question(
    image: Image.Image, 
    question: str, 
    model_manager: ModelManager,
    img_name: str
) -> Dict[str, any]:
    """ë‹¨ì¼ ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ì—¬ VLMê³¼ RAG ê²°ê³¼ë¥¼ ëª¨ë‘ ë°˜í™˜"""
    
    # ì…ë ¥ê°’ ê²€ì¦
    validate_inputs(image, question)
    question = question.strip()
    
    # ê²°ê³¼ ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬
    result = {
        "image_name": img_name,
        "question": question,
        "vlm_answer": None,
        "vlm_reasoning": None,
        "vlm_time": 0,
        "rag_answer": None,
        "rag_reasoning": None,
        "rag_context": None,
        "rag_time": 0,
        "error": None
    }
    
    try:
        # ëª¨ë¸ ìƒíƒœ ë””ë²„ê¹…
        debug_model_state(model_manager, "ì§ˆë¬¸ ì²˜ë¦¬ ì‹œì‘")
        
        # VLM ë‹¨ë… ë‹µë³€ ìƒì„± (ì‹œê°„ ì¸¡ì •)
        logger.info(f"ğŸ§  VLM ì²˜ë¦¬ ì‹œì‘: '{question[:50]}...'")
        
        vlm_start_time = time.time()
        try:
            vlm_answer, vlm_reasoning = safe_run_vlm_pipeline(
                image, 
                question, 
                model_manager.vlm, 
                model_manager.txt_tokenizer, 
                model_manager.vis_tokenizer
            )
            vlm_end_time = time.time()
            vlm_time = vlm_end_time - vlm_start_time
            
            result.update({
                "vlm_answer": vlm_answer,
                "vlm_reasoning": vlm_reasoning,
                "vlm_time": vlm_time
            })
            
            logger.info(f"VLM ì²˜ë¦¬ ì™„ë£Œ: {format_time(vlm_time)}")
            
        except Exception as e:
            logger.error(f"VLM íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}")
            result.update({
                "vlm_answer": f"VLM ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}",
                "vlm_reasoning": "VLM íŒŒì´í”„ë¼ì¸ì—ì„œ ì˜¤ë¥˜ ë°œìƒ",
                "vlm_time": 0
            })
        
        # RAG ì ìš© íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ì‹œê°„ ì¸¡ì •)
        logger.info(f"ğŸ“š RAG ì²˜ë¦¬ ì‹œì‘: '{question[:50]}...'")
        
        rag_start_time = time.time()
        try:
            rag_answer, rag_desc, rag_context = safe_run_rag_pipeline(
                image, 
                question, 
                model_manager.vlm, 
                model_manager.txt_tokenizer, 
                model_manager.vis_tokenizer, 
                model_manager.emb_model, 
                model_manager.collections
            )
            rag_end_time = time.time()
            rag_time = rag_end_time - rag_start_time
            
            result.update({
                "rag_answer": rag_answer,
                "rag_reasoning": rag_desc,
                "rag_context": rag_context,
                "rag_time": rag_time
            })
            
            logger.info(f"RAG ì²˜ë¦¬ ì™„ë£Œ: {format_time(rag_time)}")
            
        except Exception as e:
            logger.error(f"RAG íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}")
            result.update({
                "rag_answer": f"RAG ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}",
                "rag_reasoning": "RAG íŒŒì´í”„ë¼ì¸ì—ì„œ ì˜¤ë¥˜ ë°œìƒ",
                "rag_context": f"ì˜¤ë¥˜: {str(e)}",
                "rag_time": 0
            })
            
    except Exception as e:
        error_msg = str(e)
        logger.error(f"âŒ ì§ˆë¬¸ ì²˜ë¦¬ ì‹¤íŒ¨: {error_msg}")
        import traceback
        logger.error(f"ì „ì²´ íŠ¸ë ˆì´ìŠ¤ë°±:\n{traceback.format_exc()}")
        
        result["error"] = error_msg
        
        # ì‹¤íŒ¨í•œ ê²½ìš° ê¸°ë³¸ê°’ ì„¤ì •
        for key in ["vlm_answer", "vlm_reasoning", "rag_answer", "rag_reasoning", "rag_context"]:
            if result[key] is None:
                result[key] = f"ì²˜ë¦¬ ì‹¤íŒ¨: {error_msg}"
    
    return result

def create_performance_summary(results: List[Dict]) -> str:
    """ì „ì²´ ì²˜ë¦¬ ê²°ê³¼ì— ëŒ€í•œ ì„±ëŠ¥ ìš”ì•½ì„ ìƒì„±"""
    if not results:
        return "ì²˜ë¦¬ëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    # ì„±ê³µí•œ ê²°ê³¼ë§Œ í•„í„°ë§
    successful_results = [r for r in results if r["error"] is None]
    
    if not successful_results:
        return "ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    total_vlm_time = sum(r["vlm_time"] for r in successful_results)
    total_rag_time = sum(r["rag_time"] for r in successful_results)
    total_time = total_vlm_time + total_rag_time
    
    avg_vlm_time = total_vlm_time / len(successful_results)
    avg_rag_time = total_rag_time / len(successful_results)
    
    success_rate = len(successful_results) / len(results) * 100
    
    summary = f"""
ğŸ“Š **ë°°ì¹˜ ì²˜ë¦¬ ì„±ëŠ¥ ìš”ì•½**

ğŸ“ˆ **ì²˜ë¦¬ í†µê³„**
â€¢ ì´ ì§ˆë¬¸ ìˆ˜: {len(results)}ê°œ
â€¢ ì„±ê³µ ì²˜ë¦¬: {len(successful_results)}ê°œ ({success_rate:.1f}%)
â€¢ ì‹¤íŒ¨ ì²˜ë¦¬: {len(results) - len(successful_results)}ê°œ

â±ï¸ **ì‹œê°„ ë¶„ì„**
â€¢ VLM ì´ ì‹œê°„: {format_time(total_vlm_time)}
â€¢ RAG ì´ ì‹œê°„: {format_time(total_rag_time)}
â€¢ ì „ì²´ ì²˜ë¦¬ ì‹œê°„: {format_time(total_time)}

âš¡ **í‰ê·  ì²˜ë¦¬ ì‹œê°„**
â€¢ VLM í‰ê· : {format_time(avg_vlm_time)}
â€¢ RAG í‰ê· : {format_time(avg_rag_time)}
"""
    
    if avg_vlm_time > 0 and avg_rag_time > 0:
        speedup = avg_vlm_time / avg_rag_time
        if speedup > 1:
            summary += f"\nğŸš€ **ì„±ëŠ¥ ë¹„êµ**: VLMì´ RAGë³´ë‹¤ í‰ê·  {speedup:.1f}ë°° ë¹ ë¦„"
        else:
            summary += f"\nğŸš€ **ì„±ëŠ¥ ë¹„êµ**: RAGê°€ VLMë³´ë‹¤ í‰ê·  {1/speedup:.1f}ë°° ë¹ ë¦„"
    
    return summary

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    logger.info("ğŸš€ ë°°ì¹˜ ì´ë¯¸ì§€ ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ ì‹œì‘")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ í™•ì¸
    os.makedirs(os.path.dirname(OUTPUT_CSV) if os.path.dirname(OUTPUT_CSV) else ".", exist_ok=True)
    
    # ëª¨ë¸ ë§¤ë‹ˆì € ì´ˆê¸°í™” ë° ë¡œë”©
    model_manager = ModelManager()
    
    if not model_manager.load_models():
        logger.error("âŒ ëª¨ë¸ ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    # ì§ˆë¬¸ ë°ì´í„° ë¡œë“œ
    qa_map = load_questions_by_image(QUESTION_CSV)
    if not qa_map:
        logger.error("âŒ ì²˜ë¦¬í•  ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    results = []
    total_questions = sum(len(questions) for questions in qa_map.values())
    logger.info(f"ğŸ“Š ì´ {total_questions}ê°œì˜ ì§ˆë¬¸ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤")

    processed_count = 0
    error_count = 0

    with timer("ì „ì²´ ë°°ì¹˜ ì²˜ë¦¬"):
        for img_name, questions in tqdm(qa_map.items(), desc="ğŸ” ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘"):
            img_path = os.path.join(IMAGE_DIR, img_name)
            
            # ì´ë¯¸ì§€ ë¡œë“œ
            image = safe_image_load(img_path)
            if image is None:
                # ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨ì‹œ ëª¨ë“  ì§ˆë¬¸ì— ëŒ€í•´ ì˜¤ë¥˜ ê¸°ë¡
                for question in questions:
                    results.append({
                        "image_name": img_name,
                        "question": question,
                        "vlm_answer": "ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨",
                        "vlm_reasoning": "ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
                        "rag_answer": "ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨",
                        "rag_reasoning": "ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
                        "rag_context": "ì—†ìŒ"
                    })
                    error_count += 1
                continue

            # ê° ì§ˆë¬¸ ì²˜ë¦¬
            for question in questions:
                processed_count += 1
                logger.info(f"ğŸ”„ ì²˜ë¦¬ ì¤‘ [{processed_count}/{total_questions}]: {img_name} - '{question[:50]}...'")
                
                # ë‹¨ì¼ ì§ˆë¬¸ ì²˜ë¦¬
                result = process_single_question(image, question, model_manager, img_name)
                
                # CSV ì¶œë ¥ìš© í˜•íƒœë¡œ ë³€í™˜
                csv_result = {
                    "image_name": result["image_name"],
                    "question": result["question"],
                    "vlm_answer": result["vlm_answer"] or "ì²˜ë¦¬ ì‹¤íŒ¨",
                    "vlm_reasoning": result["vlm_reasoning"] or "ì¶”ë¡  ì—†ìŒ",
                    "rag_answer": result["rag_answer"] or "ì²˜ë¦¬ ì‹¤íŒ¨",
                    "rag_reasoning": result["rag_reasoning"] or "ì¶”ë¡  ì—†ìŒ",
                    "rag_context": result["rag_context"] or "ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ"
                }
                
                results.append(csv_result)
                
                if result["error"] is not None:
                    error_count += 1

    # ê²°ê³¼ CSV ì €ì¥
    fieldnames = [
        "image_name", "question",
        "vlm_answer", "vlm_reasoning",
        "rag_answer", "rag_reasoning", "rag_context"
    ]

    try:
        with open(OUTPUT_CSV, "w", newline='', encoding="utf-8") as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(results)
        
        logger.info(f"âœ… ëª¨ë“  ì²˜ë¦¬ ì™„ë£Œ!")
        logger.info(f"ğŸ“ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {OUTPUT_CSV}")
        logger.info(f"ğŸ“Š ì²˜ë¦¬ í†µê³„:")
        logger.info(f"   - ì´ ì²˜ë¦¬ëœ ì§ˆë¬¸: {processed_count}")
        logger.info(f"   - ì„±ê³µ: {processed_count - error_count}")
        logger.info(f"   - ì˜¤ë¥˜: {error_count}")
        
        # ì„±ëŠ¥ ìš”ì•½ ì¶œë ¥ (ë¡œê·¸ìš©)
        if results:
            # ì‹œê°„ ì •ë³´ê°€ ìˆëŠ” ê²°ê³¼ë“¤ë¡œ ì„±ëŠ¥ ìš”ì•½ ìƒì„± (ì‹¤ì œë¡œëŠ” ëª¨ë“  ê²°ê³¼ì— ì‹œê°„ ì •ë³´ê°€ ì—†ìœ¼ë¯€ë¡œ ê¸°ë³¸ í†µê³„ë§Œ)
            success_rate = (processed_count - error_count) / processed_count * 100 if processed_count > 0 else 0
            logger.info(f"ğŸ¯ ìµœì¢… ì„±ê³µë¥ : {success_rate:.1f}%")
        
    except Exception as e:
        logger.error(f"âŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    main()